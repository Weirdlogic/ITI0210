{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# Basic Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PslnzB4Y0xPo"
      },
      "source": [
        "### Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook setup**. Select the \"Edit\" menu, then \"Notebook settings\". Choose \"GPU\" as the hardware accelerator. Check that \"Omit code cell output...\" is unchecked (so that the output is saved).\n",
        "\n"
      ],
      "metadata": {
        "id": "o5O0p0HC03C5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Pytorch, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "BIRVWB6F-QM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aff9b40-7c9c-48a6-b925-f9e9c0ba286b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 169kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.07MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data.data.size())\n",
        "print(training_data.targets.size())\n",
        "print(test_data.data.size())\n",
        "print(test_data.targets.size())"
      ],
      "metadata": {
        "id": "W5hfcRDNQtNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84ac9a5-08a7-4043-ad26-b013c56a4623"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n",
            "torch.Size([10000, 28, 28])\n",
            "torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data of one image"
      ],
      "metadata": {
        "id": "LWeKN_HbRbR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_image, first_label = training_data[0]\n",
        "first_image = first_image.numpy().squeeze()\n",
        "print(f\"Shape of first image: {first_image.shape}\")\n",
        "print(first_image)"
      ],
      "metadata": {
        "id": "qK5hL0UsRim8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68614818-f4be-41ba-e27e-725b19be73f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of first image: (28, 28)\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627452 0.\n",
            "  0.         0.00392157 0.01568628 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.         0.14117648 0.53333336 0.49803922 0.24313726\n",
            "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
            "  0.01568628 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.02352941 0.         0.4        0.8        0.6901961  0.5254902\n",
            "  0.5647059  0.48235294 0.09019608 0.         0.         0.\n",
            "  0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784316 0.9254902  0.8117647  0.69803923\n",
            "  0.41960785 0.6117647  0.6313726  0.42745098 0.2509804  0.09019608\n",
            "  0.3019608  0.50980395 0.28235295 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.27058825 0.8117647  0.8745098  0.85490197 0.84705883\n",
            "  0.84705883 0.6392157  0.49803922 0.4745098  0.47843137 0.57254905\n",
            "  0.5529412  0.34509805 0.6745098  0.25882354]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
            "  0.         0.78431374 0.9098039  0.9098039  0.9137255  0.8980392\n",
            "  0.8745098  0.8745098  0.84313726 0.8352941  0.6431373  0.49803922\n",
            "  0.48235294 0.76862746 0.8980392  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.7176471  0.88235295 0.84705883 0.8745098  0.89411765\n",
            "  0.92156863 0.8901961  0.8784314  0.87058824 0.8784314  0.8666667\n",
            "  0.8745098  0.9607843  0.6784314  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.75686276 0.89411765 0.85490197 0.8352941  0.7764706\n",
            "  0.7058824  0.83137256 0.8235294  0.827451   0.8352941  0.8745098\n",
            "  0.8627451  0.9529412  0.7921569  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.01176471 0.\n",
            "  0.04705882 0.85882354 0.8627451  0.83137256 0.85490197 0.7529412\n",
            "  0.6627451  0.8901961  0.8156863  0.85490197 0.8784314  0.83137256\n",
            "  0.8862745  0.77254903 0.81960785 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.3882353  0.95686275 0.87058824 0.8627451  0.85490197 0.79607844\n",
            "  0.7764706  0.8666667  0.84313726 0.8352941  0.87058824 0.8627451\n",
            "  0.9607843  0.46666667 0.654902   0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568628 0.         0.\n",
            "  0.21568628 0.9254902  0.89411765 0.9019608  0.89411765 0.9411765\n",
            "  0.9098039  0.8352941  0.85490197 0.8745098  0.91764706 0.8509804\n",
            "  0.8509804  0.81960785 0.36078432 0.        ]\n",
            " [0.         0.         0.00392157 0.01568628 0.02352941 0.02745098\n",
            "  0.00784314 0.         0.         0.         0.         0.\n",
            "  0.92941177 0.8862745  0.8509804  0.8745098  0.87058824 0.85882354\n",
            "  0.87058824 0.8666667  0.84705883 0.8745098  0.8980392  0.84313726\n",
            "  0.85490197 1.         0.3019608  0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313726 0.5686275  0.8\n",
            "  0.89411765 0.8117647  0.8352941  0.8666667  0.85490197 0.8156863\n",
            "  0.827451   0.85490197 0.8784314  0.8745098  0.85882354 0.84313726\n",
            "  0.8784314  0.95686275 0.62352943 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902\n",
            "  0.32156864 0.41960785 0.7411765  0.89411765 0.8627451  0.87058824\n",
            "  0.8509804  0.8862745  0.78431374 0.8039216  0.827451   0.9019608\n",
            "  0.8784314  0.91764706 0.6901961  0.7372549  0.98039216 0.972549\n",
            "  0.9137255  0.93333334 0.84313726 0.        ]\n",
            " [0.         0.22352941 0.73333335 0.8156863  0.8784314  0.8666667\n",
            "  0.8784314  0.8156863  0.8        0.8392157  0.8156863  0.81960785\n",
            "  0.78431374 0.62352943 0.9607843  0.75686276 0.80784315 0.8745098\n",
            "  1.         1.         0.8666667  0.91764706 0.8666667  0.827451\n",
            "  0.8627451  0.9098039  0.9647059  0.        ]\n",
            " [0.01176471 0.7921569  0.89411765 0.8784314  0.8666667  0.827451\n",
            "  0.827451   0.8392157  0.8039216  0.8039216  0.8039216  0.8627451\n",
            "  0.9411765  0.3137255  0.5882353  1.         0.8980392  0.8666667\n",
            "  0.7372549  0.6039216  0.7490196  0.8235294  0.8        0.81960785\n",
            "  0.87058824 0.89411765 0.88235295 0.        ]\n",
            " [0.38431373 0.9137255  0.7764706  0.8235294  0.87058824 0.8980392\n",
            "  0.8980392  0.91764706 0.9764706  0.8627451  0.7607843  0.84313726\n",
            "  0.8509804  0.94509804 0.25490198 0.28627452 0.41568628 0.45882353\n",
            "  0.65882355 0.85882354 0.8666667  0.84313726 0.8509804  0.8745098\n",
            "  0.8745098  0.8784314  0.8980392  0.11372549]\n",
            " [0.29411766 0.8        0.83137256 0.8        0.75686276 0.8039216\n",
            "  0.827451   0.88235295 0.84705883 0.7254902  0.77254903 0.80784315\n",
            "  0.7764706  0.8352941  0.9411765  0.7647059  0.8901961  0.9607843\n",
            "  0.9372549  0.8745098  0.85490197 0.83137256 0.81960785 0.87058824\n",
            "  0.8627451  0.8666667  0.9019608  0.2627451 ]\n",
            " [0.1882353  0.79607844 0.7176471  0.7607843  0.8352941  0.77254903\n",
            "  0.7254902  0.74509805 0.7607843  0.7529412  0.7921569  0.8392157\n",
            "  0.85882354 0.8666667  0.8627451  0.9254902  0.88235295 0.84705883\n",
            "  0.78039217 0.80784315 0.7294118  0.70980394 0.69411767 0.6745098\n",
            "  0.70980394 0.8039216  0.80784315 0.4509804 ]\n",
            " [0.         0.47843137 0.85882354 0.75686276 0.7019608  0.67058825\n",
            "  0.7176471  0.76862746 0.8        0.8235294  0.8352941  0.8117647\n",
            "  0.827451   0.8235294  0.78431374 0.76862746 0.7607843  0.7490196\n",
            "  0.7647059  0.7490196  0.7764706  0.7529412  0.6901961  0.6117647\n",
            "  0.654902   0.69411767 0.8235294  0.36078432]\n",
            " [0.         0.         0.2901961  0.7411765  0.83137256 0.7490196\n",
            "  0.6862745  0.6745098  0.6862745  0.70980394 0.7254902  0.7372549\n",
            "  0.7411765  0.7372549  0.75686276 0.7764706  0.8        0.81960785\n",
            "  0.8235294  0.8235294  0.827451   0.7372549  0.7372549  0.7607843\n",
            "  0.7529412  0.84705883 0.6666667  0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882354 0.78431374\n",
            "  0.87058824 0.92941177 0.9372549  0.9490196  0.9647059  0.9529412\n",
            "  0.95686275 0.8666667  0.8627451  0.75686276 0.7490196  0.7019608\n",
            "  0.7137255  0.7137255  0.70980394 0.6901961  0.6509804  0.65882355\n",
            "  0.3882353  0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.15686275 0.23921569 0.17254902 0.28235295 0.16078432\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this is what the image looks like (a shoe?)"
      ],
      "metadata": {
        "id": "6hIlZOVySIxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(first_image, cmap='gray')"
      ],
      "metadata": {
        "id": "sCZoxyQcSL3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "d74053d6-4b9c-4bab-b8d4-bc442f58876d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c3b90b5f650>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label of the image (see the list of labels at https://github.com/zalandoresearch/fashion-mnist)"
      ],
      "metadata": {
        "id": "OiejkO3OTh0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Label of first image: {first_label}\")"
      ],
      "metadata": {
        "id": "IGyqRUNMTuU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2c2b04-a8a8-468a-9f62-bdb6b8592714"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label of first image: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put you code to create, train and test the model below"
      ],
      "metadata": {
        "id": "FRLdpO4AWXYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "NW3_QC9d59d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24c36ef-92ed-48f7-e504-175351604500"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.cnn_stack(x)\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "FwOw0DpiV73y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BDJXYUHV_Yy",
        "outputId": "c84b7a9d-24db-4cc3-80d2-0ae4069b326c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  {current:>5d}/{size:>5d}\")"
      ],
      "metadata": {
        "id": "ArkoLA12WDq_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9mgspu_WGrL",
        "outputId": "b1b0d3c8-1086-4ff5-875c-1f9ba71db1de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301435     64/60000\n",
            "loss: 0.701172   6464/60000\n",
            "loss: 0.367494  12864/60000\n",
            "loss: 0.563256  19264/60000\n",
            "loss: 0.512048  25664/60000\n",
            "loss: 0.466373  32064/60000\n",
            "loss: 0.380199  38464/60000\n",
            "loss: 0.548093  44864/60000\n",
            "loss: 0.509356  51264/60000\n",
            "loss: 0.425212  57664/60000\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.287670     64/60000\n",
            "loss: 0.343245   6464/60000\n",
            "loss: 0.210512  12864/60000\n",
            "loss: 0.405658  19264/60000\n",
            "loss: 0.393269  25664/60000\n",
            "loss: 0.377794  32064/60000\n",
            "loss: 0.295743  38464/60000\n",
            "loss: 0.429720  44864/60000\n",
            "loss: 0.394888  51264/60000\n",
            "loss: 0.323584  57664/60000\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.238973     64/60000\n",
            "loss: 0.269204   6464/60000\n",
            "loss: 0.175970  12864/60000\n",
            "loss: 0.304099  19264/60000\n",
            "loss: 0.312860  25664/60000\n",
            "loss: 0.369090  32064/60000\n",
            "loss: 0.259960  38464/60000\n",
            "loss: 0.371326  44864/60000\n",
            "loss: 0.322334  51264/60000\n",
            "loss: 0.278086  57664/60000\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.231057     64/60000\n",
            "loss: 0.237818   6464/60000\n",
            "loss: 0.159991  12864/60000\n",
            "loss: 0.250329  19264/60000\n",
            "loss: 0.279753  25664/60000\n",
            "loss: 0.340157  32064/60000\n",
            "loss: 0.245527  38464/60000\n",
            "loss: 0.344285  44864/60000\n",
            "loss: 0.283118  51264/60000\n",
            "loss: 0.208281  57664/60000\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.190761     64/60000\n",
            "loss: 0.157578   6464/60000\n",
            "loss: 0.138438  12864/60000\n",
            "loss: 0.184363  19264/60000\n",
            "loss: 0.273173  25664/60000\n",
            "loss: 0.305187  32064/60000\n",
            "loss: 0.235726  38464/60000\n",
            "loss: 0.281768  44864/60000\n",
            "loss: 0.238092  51264/60000\n",
            "loss: 0.147756  57664/60000\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.167830     64/60000\n",
            "loss: 0.138097   6464/60000\n",
            "loss: 0.127398  12864/60000\n",
            "loss: 0.162840  19264/60000\n",
            "loss: 0.241092  25664/60000\n",
            "loss: 0.277280  32064/60000\n",
            "loss: 0.207947  38464/60000\n",
            "loss: 0.248621  44864/60000\n",
            "loss: 0.216626  51264/60000\n",
            "loss: 0.110889  57664/60000\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.156702     64/60000\n",
            "loss: 0.136512   6464/60000\n",
            "loss: 0.102366  12864/60000\n",
            "loss: 0.133598  19264/60000\n",
            "loss: 0.217066  25664/60000\n",
            "loss: 0.253985  32064/60000\n",
            "loss: 0.171235  38464/60000\n",
            "loss: 0.212495  44864/60000\n",
            "loss: 0.196957  51264/60000\n",
            "loss: 0.078414  57664/60000\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.103395     64/60000\n",
            "loss: 0.115065   6464/60000\n",
            "loss: 0.080087  12864/60000\n",
            "loss: 0.156572  19264/60000\n",
            "loss: 0.232646  25664/60000\n",
            "loss: 0.218304  32064/60000\n",
            "loss: 0.175438  38464/60000\n",
            "loss: 0.223036  44864/60000\n",
            "loss: 0.162555  51264/60000\n",
            "loss: 0.059816  57664/60000\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.122974     64/60000\n",
            "loss: 0.106658   6464/60000\n",
            "loss: 0.076407  12864/60000\n",
            "loss: 0.119583  19264/60000\n",
            "loss: 0.199118  25664/60000\n",
            "loss: 0.178887  32064/60000\n",
            "loss: 0.144632  38464/60000\n",
            "loss: 0.184364  44864/60000\n",
            "loss: 0.113914  51264/60000\n",
            "loss: 0.046506  57664/60000\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.101841     64/60000\n",
            "loss: 0.080302   6464/60000\n",
            "loss: 0.082693  12864/60000\n",
            "loss: 0.099422  19264/60000\n",
            "loss: 0.152503  25664/60000\n",
            "loss: 0.181615  32064/60000\n",
            "loss: 0.156039  38464/60000\n",
            "loss: 0.178589  44864/60000\n",
            "loss: 0.087585  51264/60000\n",
            "loss: 0.045377  57664/60000\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.126788     64/60000\n",
            "loss: 0.062408   6464/60000\n",
            "loss: 0.083575  12864/60000\n",
            "loss: 0.106226  19264/60000\n",
            "loss: 0.122341  25664/60000\n",
            "loss: 0.171055  32064/60000\n",
            "loss: 0.128961  38464/60000\n",
            "loss: 0.168051  44864/60000\n",
            "loss: 0.071444  51264/60000\n",
            "loss: 0.045153  57664/60000\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.158500     64/60000\n",
            "loss: 0.088617   6464/60000\n",
            "loss: 0.061181  12864/60000\n",
            "loss: 0.042316  19264/60000\n",
            "loss: 0.144087  25664/60000\n",
            "loss: 0.171792  32064/60000\n",
            "loss: 0.103185  38464/60000\n",
            "loss: 0.142083  44864/60000\n",
            "loss: 0.121832  51264/60000\n",
            "loss: 0.045053  57664/60000\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.103135     64/60000\n",
            "loss: 0.047005   6464/60000\n",
            "loss: 0.035758  12864/60000\n",
            "loss: 0.034464  19264/60000\n",
            "loss: 0.152550  25664/60000\n",
            "loss: 0.146071  32064/60000\n",
            "loss: 0.105360  38464/60000\n",
            "loss: 0.141967  44864/60000\n",
            "loss: 0.068363  51264/60000\n",
            "loss: 0.047400  57664/60000\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.137365     64/60000\n",
            "loss: 0.047113   6464/60000\n",
            "loss: 0.028232  12864/60000\n",
            "loss: 0.030419  19264/60000\n",
            "loss: 0.074322  25664/60000\n",
            "loss: 0.118194  32064/60000\n",
            "loss: 0.167775  38464/60000\n",
            "loss: 0.094119  44864/60000\n",
            "loss: 0.080058  51264/60000\n",
            "loss: 0.029926  57664/60000\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.081247     64/60000\n",
            "loss: 0.094086   6464/60000\n",
            "loss: 0.013554  12864/60000\n",
            "loss: 0.043578  19264/60000\n",
            "loss: 0.088771  25664/60000\n",
            "loss: 0.102870  32064/60000\n",
            "loss: 0.076153  38464/60000\n",
            "loss: 0.055804  44864/60000\n",
            "loss: 0.069719  51264/60000\n",
            "loss: 0.030698  57664/60000\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "all_outputs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dataloader:\n",
        "        outputs = model(inputs.to(device))\n",
        "        all_outputs.append(outputs)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "all_outputs = torch.cat(all_outputs, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)"
      ],
      "metadata": {
        "id": "FrRyPZpQWqFC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_outputs[0])\n",
        "print(torch.sum(all_outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ghiXpaWtY0",
        "outputId": "08e6683c-731f-4b02-ac66-b6493225c714"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-22.2931,  -5.1134, -22.8871, -13.0950, -12.6773, -12.4961,  -5.8991,\n",
            "          3.8274, -14.5158,  16.3066], device='cuda:0')\n",
            "tensor(-88.8429, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_image, _ = test_data[0]\n",
        "first_image = first_image.numpy().squeeze()\n",
        "plt.imshow(first_image, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "UWx9oR1SWvGS",
        "outputId": "82577850-24d4-4bd1-fd84-d57f2c263434"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c3b90a14c10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.argmax(all_outputs[0]))\n",
        "print(all_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzoMw9-Wxf7",
        "outputId": "b5cb98cb-294c-429a-d538-69074deea571"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9, device='cuda:0')\n",
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = torch.argmax(all_outputs, dim=1)\n",
        "correct = torch.sum(all_preds.cpu() == all_labels)\n",
        "print(\"Correct classes: {} of {} (accuracy: {})\".format(correct, 10000, correct/10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lse3UzDW1fz",
        "outputId": "70ccd937-6315-40ec-d187-fb126397e3ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct classes: 9090 of 10000 (accuracy: 0.9089999794960022)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "x4HI2mpwlrcn"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}